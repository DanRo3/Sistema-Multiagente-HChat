{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/1_build_vector_store.ipynb\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Añadir el directorio raíz del proyecto al path para importar módulos propios\n",
    "# Esto asume que ejecutas el notebook desde la raíz del proyecto\n",
    "project_root = Path.cwd() # O especifica la ruta si es diferente\n",
    "sys.path.append(str(project_root))\n",
    "print(f\"Project root added to path: {project_root}\")\n",
    "\n",
    "# Importar funciones de embeddings y configuración\n",
    "# Asegúrate de que config.py y embeddings.py funcionen correctamente antes\n",
    "try:\n",
    "    from app.core.embeddings import get_embeddings, get_embedding_model\n",
    "    from app.core.config import settings\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Please ensure you are running this notebook from the project root directory\")\n",
    "    print(\"and that the app structure and __init__.py files are correct.\")\n",
    "    sys.exit(1) # Salir si no se pueden importar\n",
    "\n",
    "# --- 1. Cargar Datos ---\n",
    "data_path = project_root / \"data/raw_data.csv\"\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    # Asegúrate de que la columna con el texto principal se llame 'Texto' o ajústalo\n",
    "    if 'Texto' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain a 'Texto' column.\")\n",
    "    print(f\"Data loaded successfully. Shape: {df.shape}\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {data_path}\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- 2. Generar Embeddings ---\n",
    "texts_to_embed = df['Texto'].tolist()\n",
    "print(f\"Generating embeddings for {len(texts_to_embed)} documents...\")\n",
    "# Usamos la función get_embeddings que maneja la carga del modelo\n",
    "embeddings = get_embeddings(texts_to_embed)\n",
    "embeddings_np = np.array(embeddings).astype('float32') # FAISS requiere numpy float32\n",
    "print(f\"Embeddings generated. Shape: {embeddings_np.shape}\")\n",
    "\n",
    "# --- 3. Construir Índice FAISS ---\n",
    "dimension = embeddings_np.shape[1] # Dimensión de los embeddings\n",
    "# Usaremos un índice simple FlatL2 para empezar (búsqueda exacta)\n",
    "# Para datasets grandes, considera IndexIVFFlat o IndexHNSWFlat\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "# index = faiss.IndexIDMap(index) # Opcional: para mapear IDs de FAISS a IDs originales\n",
    "\n",
    "print(\"Adding embeddings to FAISS index...\")\n",
    "# Si usas IndexIDMap:\n",
    "# ids = df['ID'].values.astype('int64') # Asegúrate de que los IDs son int64\n",
    "# index.add_with_ids(embeddings_np, ids)\n",
    "# Si NO usas IndexIDMap (los IDs serán las posiciones 0, 1, 2...):\n",
    "index.add(embeddings_np)\n",
    "\n",
    "print(f\"Index built. Total vectors in index: {index.ntotal}\")\n",
    "\n",
    "# --- 4. Guardar Índice y Metadatos ---\n",
    "# Crear directorio si no existe\n",
    "settings.faiss_index_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Saving FAISS index to: {settings.faiss_index_path}\")\n",
    "faiss.write_index(index, str(settings.faiss_index_path))\n",
    "\n",
    "# Guardar metadatos (ej: mapeo de índice FAISS a texto original o ID del CSV)\n",
    "# Si NO usaste IndexIDMap, el ID de FAISS es la posición en la lista original\n",
    "metadata = {i: {'text': text, 'original_id': df.iloc[i]['ID']}\n",
    "            for i, text in enumerate(texts_to_embed)}\n",
    "# Si SÍ usaste IndexIDMap, el ID ya está en el índice, podrías guardar solo texto vs ID original\n",
    "# metadata = df.set_index('ID')['Texto'].to_dict() # Ejemplo\n",
    "\n",
    "print(f\"Saving metadata to: {settings.faiss_metadata_path}\")\n",
    "with open(settings.faiss_metadata_path, 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(\"Index and metadata saved successfully.\")\n",
    "\n",
    "# --- 5. Prueba Rápida (Opcional) ---\n",
    "print(\"\\n--- Quick Test ---\")\n",
    "try:\n",
    "    # Cargar modelo solo para query (o reutilizar)\n",
    "    query_text = \"Información sobre ventas del producto A\"\n",
    "    query_embedding = get_embedding_model().embed_query(query_text)\n",
    "    query_embedding_np = np.array([query_embedding]).astype('float32')\n",
    "\n",
    "    k = 3 # Número de vecinos más cercanos a buscar\n",
    "    print(f\"Searching for top {k} similar documents for query: '{query_text}'\")\n",
    "    distances, indices = index.search(query_embedding_np, k)\n",
    "\n",
    "    print(\"Results:\")\n",
    "    for i in range(k):\n",
    "        faiss_id = indices[0][i]\n",
    "        distance = distances[0][i]\n",
    "        # Recuperar metadatos usando el índice FAISS devuelto\n",
    "        doc_info = metadata.get(faiss_id, {\"text\": \"Metadata not found\"})\n",
    "        print(f\"  - Rank {i+1}: FAISS ID {faiss_id}, Distance: {distance:.4f}\")\n",
    "        print(f\"    Text: {doc_info.get('text', 'N/A')}\")\n",
    "        print(f\"    Original ID: {doc_info.get('original_id', 'N/A')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during quick test: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
